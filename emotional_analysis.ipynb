{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import sys\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'DATA',\n",
       " 'emotional_analysis.ipynb',\n",
       " 'model',\n",
       " 'test.txt',\n",
       " 'train.txt',\n",
       " 'val.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.txt', sep = ';', names = ['message', 'emot'])\n",
    "test = pd.read_csv('test.txt', sep = ';', names = ['message', 'emot'])\n",
    "val = pd.read_csv('val.txt', sep = ';', names = ['message', 'emot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test, val], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {emot:len(df[df['emot'] == emot]['emot']) for emot in set(df['emot'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.bar(emotions.keys(), emotions.values(), width = 0.7, color = 'green')\n",
    "ax.set_xlabel('Emotion', fontsize = 20, color = 'white')\n",
    "ax.set_ylabel('Amount', fontsize = 20, color = 'white')\n",
    "ax.set_xticklabels(labels = emotions.keys(), color = 'white', fontsize = 12, rotation = 45)\n",
    "ax.set_yticklabels(labels = emotions.values(), color = 'white', fontsize = 12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>emot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 message     emot\n",
       "0                                i didnt feel humiliated  sadness\n",
       "1      i can go from feeling so hopeless to so damned...  sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong    anger\n",
       "3      i am ever feeling nostalgic about the fireplac...     love\n",
       "4                                   i am feeling grouchy    anger\n",
       "...                                                  ...      ...\n",
       "15995  i just had a very brief time in the beanbag an...  sadness\n",
       "15996  i am now turning and i feel pathetic that i am...  sadness\n",
       "15997                     i feel strong and good overall      joy\n",
       "15998  i feel like this was such a rude comment and i...    anger\n",
       "15999  i know a lot but i feel so stupid because i ca...  sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_processing(text):\n",
    "    review = text.lower()\n",
    "    review = re.sub('/s+', ' ', review)\n",
    "    review = re.sub('/d', '', review)\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    \n",
    "    lem = WordNetLemmatizer()\n",
    "    tokens = [lem.lemmatize(word) for word in tokens if word not in stopwords.words('english')]\n",
    "    \n",
    "    sent = ' '.join(tokens)\n",
    "\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train['message'].apply(text_processing), train['emot']], axis = 1)\n",
    "test = pd.concat([test['message'].apply(text_processing), test['emot']], axis = 1)\n",
    "val = pd.concat([val['message'].apply(text_processing), val['emot']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_dir.exists():\n",
    "    os.mkdir(data_dir)\n",
    "\n",
    "with open(data_dir/'train.pkl', 'wb') as file:\n",
    "    pickle.dump(train, file)\n",
    "    \n",
    "with open(data_dir/'test.pkl', 'wb') as file:\n",
    "    pickle.dump(test, file)\n",
    "    \n",
    "with open(data_dir/'val.pkl', 'wb') as file:\n",
    "    pickle.dump(val, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 5000 \n",
    "sent_len = 40\n",
    "features = 10\n",
    "\n",
    "data_dir = Path.cwd()/'DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(text, vocabulary_size = 5000, sent_len = 40):\n",
    "    one_hot_rep = [one_hot(text, vocabulary_size )]\n",
    "    vector = pad_sequences(one_hot_rep, maxlen = sent_len, padding = 'pre')\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = set(pd.concat([train['emot'], test['emot'], val['emot']], axis = 0))\n",
    "class_mapper = {emot:number for number,emot in enumerate(all_classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['message'].apply(vectorizer)\n",
    "X_train = np.array([i for i in X_train]).reshape(-1, sent_len)\n",
    "y_train = tf.keras.utils.to_categorical(np.array(train['emot'].map(class_mapper)))\n",
    "\n",
    "X_test = test['message'].apply(vectorizer)\n",
    "X_test = np.array([i for i in X_test]).reshape(-1, sent_len)\n",
    "y_test = tf.keras.utils.to_categorical(np.array(test['emot'].map(class_mapper)))\n",
    "\n",
    "X_val = val['message'].apply(vectorizer)\n",
    "X_val = np.array([i for i in X_val]).reshape(-1, sent_len)\n",
    "y_val = tf.keras.utils.to_categorical(np.array(val['emot'].map(class_mapper)))\n",
    "\n",
    "datas = {'X_train':X_train, 'y_train':y_train, 'X_test':X_test,\n",
    "          'y_test':y_test, 'X_val':X_val, 'y_val':y_val}\n",
    "\n",
    "for i in datas.keys():\n",
    "    path = i + '.pkl'\n",
    "    with open(data_dir/path, 'wb') as file:\n",
    "        pickle.dump(datas[i], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "        with open(data_dir/'X_train.pkl', 'rb') as file:\n",
    "            X_train = pickle.load(file)\n",
    "        with open(data_dir/'y_train.pkl', 'rb') as file:\n",
    "            y_train = pickle.load(file)\n",
    "    \n",
    "        with open(data_dir/'X_test.pkl', 'rb') as file:\n",
    "            X_test = pickle.load(file)\n",
    "        with open(data_dir/'y_test.pkl', 'rb') as file:\n",
    "            y_test = pickle.load(file)\n",
    "            \n",
    "        with open(data_dir/'X_val.pkl', 'rb') as file:\n",
    "            X_val = pickle.load(file)\n",
    "        with open(data_dir/'y_val.pkl', 'rb') as file:\n",
    "            y_val = pickle.load(file)\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    X_train *2\n",
    "    y_train *2\n",
    "except:\n",
    "    X_train, y_train, X_test, y_test, X_val, y_val = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocabulary_size, output_dim = features, input_length = sent_len))\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(LSTM(100, return_sequences = True, activation = 'relu'))\n",
    "model.add(Dropout(rate = 0.1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(units = len(y_train[0]), activation = 'sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = 'accuracy')\n",
    "reductor = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 5, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 116s 411ms/step - loss: 1.6110 - accuracy: 0.3340 - val_loss: 1.3505 - val_accuracy: 0.5180\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 82s 328ms/step - loss: 1.1228 - accuracy: 0.5827 - val_loss: 0.8484 - val_accuracy: 0.6550\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 45s 181ms/step - loss: 0.7215 - accuracy: 0.7163 - val_loss: 0.7073 - val_accuracy: 0.7370\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.5351 - accuracy: 0.8092 - val_loss: 0.5335 - val_accuracy: 0.8135\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 50s 201ms/step - loss: 0.4130 - accuracy: 0.8606 - val_loss: 0.4714 - val_accuracy: 0.8375\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 42s 170ms/step - loss: 0.3287 - accuracy: 0.8897 - val_loss: 0.4515 - val_accuracy: 0.8475\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 42s 170ms/step - loss: 0.2776 - accuracy: 0.9038 - val_loss: 0.4458 - val_accuracy: 0.8425\n",
      "Epoch 8/50\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.2577 - accuracy: 0.9114 - val_loss: 0.4381 - val_accuracy: 0.8470\n",
      "Epoch 9/50\n",
      "250/250 [==============================] - 68s 274ms/step - loss: 0.2439 - accuracy: 0.9164 - val_loss: 0.4342 - val_accuracy: 0.8495\n",
      "Epoch 10/50\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.2210 - accuracy: 0.9194 - val_loss: 0.4369 - val_accuracy: 0.8540\n",
      "Epoch 11/50\n",
      "250/250 [==============================] - 55s 219ms/step - loss: 0.1953 - accuracy: 0.9286 - val_loss: 0.4163 - val_accuracy: 0.8670\n",
      "Epoch 12/50\n",
      "250/250 [==============================] - 68s 272ms/step - loss: 0.1852 - accuracy: 0.9339 - val_loss: 0.4452 - val_accuracy: 0.8620\n",
      "Epoch 13/50\n",
      "250/250 [==============================] - 66s 263ms/step - loss: 0.1745 - accuracy: 0.9368 - val_loss: 0.4400 - val_accuracy: 0.8665\n",
      "Epoch 14/50\n",
      "250/250 [==============================] - 75s 300ms/step - loss: 0.1759 - accuracy: 0.9364 - val_loss: 0.4382 - val_accuracy: 0.8650\n",
      "Epoch 15/50\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.1679 - accuracy: 0.9369 - val_loss: 0.4944 - val_accuracy: 0.8490\n",
      "Epoch 16/50\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.1648 - accuracy: 0.9413 - val_loss: 0.4515 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 17/50\n",
      "250/250 [==============================] - 61s 245ms/step - loss: 0.1353 - accuracy: 0.9522 - val_loss: 0.4580 - val_accuracy: 0.8640\n",
      "Epoch 18/50\n",
      "250/250 [==============================] - 55s 221ms/step - loss: 0.1312 - accuracy: 0.9525 - val_loss: 0.4600 - val_accuracy: 0.8620\n",
      "Epoch 19/50\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.1243 - accuracy: 0.9533 - val_loss: 0.4717 - val_accuracy: 0.8630\n",
      "Epoch 20/50\n",
      "250/250 [==============================] - 69s 275ms/step - loss: 0.1193 - accuracy: 0.9547 - val_loss: 0.4806 - val_accuracy: 0.8570\n",
      "Epoch 21/50\n",
      "250/250 [==============================] - 59s 238ms/step - loss: 0.1106 - accuracy: 0.9581 - val_loss: 0.4819 - val_accuracy: 0.8570\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 22/50\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.1163 - accuracy: 0.9576 - val_loss: 0.4851 - val_accuracy: 0.8570\n",
      "Epoch 23/50\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.1066 - accuracy: 0.9610 - val_loss: 0.4946 - val_accuracy: 0.8585\n",
      "Epoch 24/50\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.1140 - accuracy: 0.9580 - val_loss: 0.4952 - val_accuracy: 0.8590\n",
      "Epoch 25/50\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.1077 - accuracy: 0.9608 - val_loss: 0.4997 - val_accuracy: 0.8585\n",
      "Epoch 26/50\n",
      "250/250 [==============================] - 51s 205ms/step - loss: 0.1150 - accuracy: 0.9589 - val_loss: 0.5034 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 27/50\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.1091 - accuracy: 0.9602 - val_loss: 0.5046 - val_accuracy: 0.8570\n",
      "Epoch 28/50\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 0.1203 - accuracy: 0.9548 - val_loss: 0.5046 - val_accuracy: 0.8575\n",
      "Epoch 29/50\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.1078 - accuracy: 0.9592 - val_loss: 0.5046 - val_accuracy: 0.8595\n",
      "Epoch 30/50\n",
      "250/250 [==============================] - 78s 312ms/step - loss: 0.1119 - accuracy: 0.9584 - val_loss: 0.5056 - val_accuracy: 0.8565\n",
      "Epoch 31/50\n",
      "250/250 [==============================] - 67s 270ms/step - loss: 0.1164 - accuracy: 0.9595 - val_loss: 0.5041 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 32/50\n",
      "250/250 [==============================] - 77s 307ms/step - loss: 0.1157 - accuracy: 0.9564 - val_loss: 0.5043 - val_accuracy: 0.8580\n",
      "Epoch 33/50\n",
      "250/250 [==============================] - 74s 295ms/step - loss: 0.1195 - accuracy: 0.9549 - val_loss: 0.5044 - val_accuracy: 0.8585\n",
      "Epoch 34/50\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.1113 - accuracy: 0.9582 - val_loss: 0.5049 - val_accuracy: 0.8580\n",
      "Epoch 35/50\n",
      "250/250 [==============================] - 60s 242ms/step - loss: 0.1051 - accuracy: 0.9622 - val_loss: 0.5050 - val_accuracy: 0.8585\n",
      "Epoch 36/50\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.1112 - accuracy: 0.9580 - val_loss: 0.5056 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Epoch 37/50\n",
      "250/250 [==============================] - 58s 230ms/step - loss: 0.1148 - accuracy: 0.9566 - val_loss: 0.5055 - val_accuracy: 0.8595\n",
      "Epoch 38/50\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.1110 - accuracy: 0.9586 - val_loss: 0.5056 - val_accuracy: 0.8595\n",
      "Epoch 39/50\n",
      "250/250 [==============================] - 62s 246ms/step - loss: 0.1157 - accuracy: 0.9584 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 40/50\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 0.1119 - accuracy: 0.9589 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 41/50\n",
      "250/250 [==============================] - 68s 271ms/step - loss: 0.1147 - accuracy: 0.9588 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "Epoch 42/50\n",
      "250/250 [==============================] - 83s 332ms/step - loss: 0.1113 - accuracy: 0.9614 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 43/50\n",
      "250/250 [==============================] - 70s 281ms/step - loss: 0.1123 - accuracy: 0.9589 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 44/50\n",
      "250/250 [==============================] - 63s 254ms/step - loss: 0.1096 - accuracy: 0.9595 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 45/50\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.1106 - accuracy: 0.9591 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 46/50\n",
      "250/250 [==============================] - 63s 251ms/step - loss: 0.1105 - accuracy: 0.9598 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "Epoch 47/50\n",
      "250/250 [==============================] - 77s 307ms/step - loss: 0.1111 - accuracy: 0.9589 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 48/50\n",
      "250/250 [==============================] - 69s 277ms/step - loss: 0.1107 - accuracy: 0.9609 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 49/50\n",
      "250/250 [==============================] - 76s 302ms/step - loss: 0.1095 - accuracy: 0.9603 - val_loss: 0.5055 - val_accuracy: 0.8590\n",
      "Epoch 50/50\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.1107 - accuracy: 0.9578 - val_loss: 0.5055 - val_accuracy: 0.8590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bee72811c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data = (X_val, y_val), batch_size = 64,\n",
    "          epochs = 50, callbacks = [reductor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: A:\\ML\\NLP\\Emotional_analysis\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: A:\\ML\\NLP\\Emotional_analysis\\model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(Path.cwd()/'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(X, y, model, what_data, class_mapper):\n",
    "    print('___________________{0} DATA___________________'.format(what_data.upper()))\n",
    "    class_mapper = {class_mapper[key]: key for key in class_mapper.keys()}\n",
    "    y_pred = model.predict(X)\n",
    "    y = [i.argmax() for i in y]\n",
    "    y_pred= [i.argmax() for i in y_pred]\n",
    "\n",
    "    all_classes = set(y)\n",
    "    \n",
    "    class_index = {_class:[number for number,i in enumerate(y) if i == _class] for _class in all_classes}    \n",
    "        \n",
    "    def class_accuracy(_class, _index, y, y_pred, class_mapper):\n",
    "        y = [y[i] for i in _index]\n",
    "        y_pred = [y_pred[i] for i in _index]\n",
    "\n",
    "        accuracy = round(accuracy_score(y, y_pred), ndigits = 2, )*100\n",
    "        print('For {0} accuracy = {1}%'.format(class_mapper[_class].upper(), accuracy))\n",
    "            \n",
    "    for i in all_classes:\n",
    "        class_accuracy(i, class_index[i], y, y_pred, class_mapper)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    accuracy = round(accuracy_score(y, y_pred), ndigits = 2, )*100\n",
    "    precision = round(precision_score(y, y_pred, average = 'weighted'), ndigits = 2)*100\n",
    "    recall = round(recall_score(y, y_pred, average = 'weighted'), ndigits = 2)*100\n",
    "    f1 = round(f1_score(y, y_pred, average = 'weighted'), ndigits = 2)\n",
    "    \n",
    "    print('Accuracy = {0}%'.format(accuracy))\n",
    "    print('Precision = {0}%'.format(precision))\n",
    "    print('Recall = {0}%'.format(recall))\n",
    "    print('F1-score = {0}'.format(f1))\n",
    "    print('_______________________________________________')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________TRAIN DATA___________________\n",
      "For JOY accuracy = 96.0%\n",
      "For SADNESS accuracy = 97.0%\n",
      "For ANGER accuracy = 93.0%\n",
      "For SURPRISE accuracy = 86.0%\n",
      "For LOVE accuracy = 99.0%\n",
      "For FEAR accuracy = 98.0%\n",
      "Accuracy = 97.0%\n",
      "Precision = 97.0%\n",
      "Recall = 97.0%\n",
      "F1-score = 0.97\n",
      "_______________________________________________\n",
      "___________________TEST DATA___________________\n",
      "For JOY accuracy = 75.0%\n",
      "For SADNESS accuracy = 87.0%\n",
      "For ANGER accuracy = 81.0%\n",
      "For SURPRISE accuracy = 64.0%\n",
      "For LOVE accuracy = 91.0%\n",
      "For FEAR accuracy = 87.0%\n",
      "Accuracy = 86.0%\n",
      "Precision = 86.0%\n",
      "Recall = 86.0%\n",
      "F1-score = 0.86\n",
      "_______________________________________________\n",
      "___________________VALIDATION DATA___________________\n",
      "For JOY accuracy = 75.0%\n",
      "For SADNESS accuracy = 84.0%\n",
      "For ANGER accuracy = 79.0%\n",
      "For SURPRISE accuracy = 77.0%\n",
      "For LOVE accuracy = 94.0%\n",
      "For FEAR accuracy = 86.0%\n",
      "Accuracy = 86.0%\n",
      "Precision = 86.0%\n",
      "Recall = 86.0%\n",
      "F1-score = 0.86\n",
      "_______________________________________________\n"
     ]
    }
   ],
   "source": [
    "validation(X_train, y_train, model, 'train', class_mapper)\n",
    "validation(X_test, y_test, model, 'test', class_mapper)\n",
    "validation(X_val, y_val, model, 'validation', class_mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
